{"version":3,"sources":["robot.jpg","App.js","reportWebVitals.js","index.js"],"names":["App","recognitionRef","useRef","textRef","useState","forceUpdate","textAreaRef","useEffect","recognition","webkitSpeechRecognition","speechRecognitionList","webkitSpeechGrammarList","addFromString","grammars","lang","interimResults","maxAlternatives","current","onresult","event","a","newText","results","transcript","ta","resizableTextArea","textArea","scrollTop","scrollHeight","data","prompt","length","fetch","body","JSON","stringify","response","json","reply","replies","uter","SpeechSynthesisUtterance","pitch","rate","speechSynthesis","speak","isVisible","setIsVisible","closeModal","className","title","visible","onOk","cancelText","onCancel","Title","level","src","robot","alt","onClick","start","console","log","TextArea","ref","value","onChange","args","rows","reportWebVitals","onPerfEntry","Function","then","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"kRAAe,MAA0B,kC,OCwG1BA,MAlGf,WACE,IAAMC,EAAiBC,iBAAO,MACxBC,EAAUD,iBAAO,IAFV,EAGWE,mBAAS,IAAxBC,EAHI,oBAIPC,EAAcJ,iBAAO,MAE3BK,qBAAU,WACR,IACMC,EAAc,IAAIC,wBAClBC,EAAwB,IAAIC,wBAClCD,EAAsBE,cAHN,qMAG6B,GAC7CJ,EAAYK,SAAWH,EAEvBF,EAAYM,KAAO,QACnBN,EAAYO,gBAAiB,EAC7BP,EAAYQ,gBAAkB,EAC9Bf,EAAegB,QAAUT,EAEzBA,EAAYU,SAAZ,uCAAuB,WAAeC,GAAf,2BAAAC,EAAA,6DACfC,EAAUF,EAAMG,QAAQ,GAAG,GAAGC,WACpCpB,EAAQc,QAAR,UAAqBd,EAAQc,QAA7B,aAAyCI,EAAzC,KACAhB,EAAY,KACNmB,EAAKlB,EAAYW,QAAQQ,kBAAkBC,UAC9CC,UAAYH,EAAGI,aACZC,EAAO,CACXC,OAAO,GAAD,OAAKT,EAAL,KACNU,OAAQV,EAAQU,QARG,SAUEC,MAAM,yCAA0C,CACrE,QAAW,CACT,OAAU,MACV,kBAAmB,0BACnB,eAAgB,2BAChB,iBAAkB,QAClB,iBAAkB,OAClB,iBAAkB,cAEpB,eAAkB,cAClBC,KAAMC,KAAKC,UAAUN,GACrB,OAAU,OACV,KAAQ,OACR,YAAe,SAvBI,cAUfO,EAVe,iBAyBFA,EAASC,OAzBP,QAyBfA,EAzBe,OA0BfC,EAAQD,EAAKE,QAAQ,GAC3BpC,EAAQc,QAAR,UAAqBd,EAAQc,QAA7B,aAAyCqB,GACzCjC,EAAY,IACZmB,EAAGG,UAAYH,EAAGI,cACdY,EAAO,IAAIC,yBAAyBH,IACnCxB,KAAO,QACZ0B,EAAKE,MAAQ,IACbF,EAAKG,KAAO,IACZC,gBAAgBC,MAAML,GAlCD,4CAAvB,wDAoCC,IAGH,IAzDa,EAkEqBpC,oBAAS,GAlE9B,mBAkEN0C,EAlEM,KAkEKC,EAlEL,KAmEPC,EAAa,WACjBD,GAAa,IAGf,OACE,sBAAKE,UAAU,MAAf,UACE,eAAC,IAAD,CAAOA,UAAU,QAAQC,MAAM,+DAAaC,QAASL,EAAWM,KAAMJ,EAAYK,WAAW,eAAKC,SAAUN,EAA5G,UACE,cAAC,IAAWO,MAAZ,CAAkBC,MAAO,EAAzB,kKAGA,+BACE,qIACA,4OACA,qLAGJ,qBAAKP,UAAU,YAAYQ,IAAKC,EAAOC,IAAI,GAAGC,QA1B9B,WAClB3D,EAAegB,QAAQ4C,QACvBC,QAAQC,IAAI,wCAyBV,sBAAKd,UAAU,QAAf,UACE,cAAC,IAAWM,MAAZ,oGACA,cAAC,IAAMS,SAAP,CACEC,IAAK3D,EACL2C,UAAU,WACViB,MAAO/D,EAAQc,QACfkD,SA5Ba,WAAc,IAAD,uBAATC,EAAS,yBAATA,EAAS,gBAChCN,QAAQC,IAAIK,IA4BNC,KAAM,YCrFDC,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,8BAAqBC,MAAK,YAAkD,IAA/CC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAQP,OCDdQ,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1Bb,M","file":"static/js/main.cd0f746d.chunk.js","sourcesContent":["export default __webpack_public_path__ + \"static/media/robot.26134c8c.jpg\";","/* eslint-disable no-undef */\nimport { Input, Modal, Typography } from 'antd';\nimport robot from './robot.jpg';\nimport './App.css';\nimport { useEffect, useRef, useState } from 'react';\n\nfunction App() {\n  const recognitionRef = useRef(null);\n  const textRef = useRef('');\n  const [, forceUpdate] = useState({});\n  const textAreaRef = useRef(null);\n\n  useEffect(() => {\n    const grammar = '#JSGF V1.0; grammar colors; public <color> = белый | розовый | черный | серый ;'\n    const recognition = new webkitSpeechRecognition();\n    const speechRecognitionList = new webkitSpeechGrammarList();\n    speechRecognitionList.addFromString(grammar, 1);\n    recognition.grammars = speechRecognitionList;\n    //recognition.continuous = false;\n    recognition.lang = 'ru-RU';\n    recognition.interimResults = false;\n    recognition.maxAlternatives = 1;\n    recognitionRef.current = recognition;\n\n    recognition.onresult = async function(event) {\n      const newText = event.results[0][0].transcript;\n      textRef.current = `${textRef.current}\\n${newText}.`;\n      forceUpdate({});\n      const ta = textAreaRef.current.resizableTextArea.textArea;\n      ta.scrollTop = ta.scrollHeight;\n      const data = {\n        prompt: `${newText}.`,\n        length: newText.length,\n      }\n      const response = await fetch(\"https://pelevin.gpt.dobro.ai/generate/\", {\n        \"headers\": {\n          \"accept\": \"*/*\",\n          \"accept-language\": \"en-US,en;q=0.9,ru;q=0.8\",\n          \"content-type\": \"text/plain;charset=UTF-8\",\n          \"sec-fetch-dest\": \"empty\",\n          \"sec-fetch-mode\": \"cors\",\n          \"sec-fetch-site\": \"cross-site\"\n        },\n        \"referrerPolicy\": \"no-referrer\",\n        body: JSON.stringify(data),\n        \"method\": \"POST\",\n        \"mode\": \"cors\",\n        \"credentials\": \"omit\"\n      });\n      const json = await response.json();\n      const reply = json.replies[1];\n      textRef.current = `${textRef.current}\\n${reply}`;\n      forceUpdate({});\n      ta.scrollTop = ta.scrollHeight;\n      var uter = new SpeechSynthesisUtterance(reply);\n      uter.lang = 'ru-RU';\n      uter.pitch = 0.01;\n      uter.rate = 2.3;\n      speechSynthesis.speak(uter);\n    };\n  }, []);\n\n\n  const handleClick = () => {\n    recognitionRef.current.start();\n    console.log('Ready to receive a color command.');\n  };\n\n  const handleChange = (...args) => {\n    console.log(args);\n  }\n\n  const [isVisible, setIsVisible] = useState(true);\n  const closeModal = () => {\n    setIsVisible(false);\n  }\n\n  return (\n    <div className=\"App\">\n      <Modal className=\"modal\" title=\"Инструкция\" visible={isVisible} onOk={closeModal} cancelText=\"Ок\" onCancel={closeModal}>\n        <Typography.Title level={2}>\n          Чтобы поговорить с Оракулом:\n        </Typography.Title>\n        <ol>\n          <li>Нажмите на его лицо</li>\n          <li>Разрешите браузеру доступ к микрофону</li>\n          <li>Задайте ваш вопрос голосом</li>\n        </ol>\n      </Modal>\n      <img className=\"robot-img\" src={robot} alt=\"\" onClick={handleClick} />\n      <div className=\"right\">\n        <Typography.Title>Оракул отвечает</Typography.Title>\n        <Input.TextArea\n          ref={textAreaRef}\n          className=\"textarea\"\n          value={textRef.current}\n          onChange={handleChange}\n          rows={13}\n        />\n      </div>\n    </div>\n  );\n}\n\nexport default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}